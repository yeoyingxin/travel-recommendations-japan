{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddad653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import minsearch\n",
    "\n",
    "from qdrant_client import QdrantClient, models\n",
    "import re\n",
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from fastembed import TextEmbedding\n",
    "import numpy as np\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b167697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise gpt\n",
    "load_dotenv()  # loads from .env\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "71ae0fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "qd_client = QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb88f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample dataset due to limits for llm\n",
    "df = pl.read_csv(\"../data/japantravel_posts_with_comments.csv\")\n",
    "\n",
    "df = df.with_columns(pl.col('selftext').fill_null(''),\n",
    "                     pl.col('comment1').fill_null(''),\n",
    "                     pl.col('comment2').fill_null(''),\n",
    "                     pl.col('comment3').fill_null(''),\n",
    "                     pl.col('comment4').fill_null(''),\n",
    "                     pl.col('comment5').fill_null(''))\n",
    "df = df.with_columns(\n",
    "    (\n",
    "        \"Comment 1: \" + pl.col(\"comment1\") + \"\\n\" +\n",
    "        \"Comment 2: \" + pl.col(\"comment2\") + \"\\n\" +\n",
    "        \"Comment 3: \" + pl.col(\"comment3\") + \"\\n\" +\n",
    "        \"Comment 4: \" + pl.col(\"comment4\") + \"\\n\" +\n",
    "        \"Comment 5: \" + pl.col(\"comment5\")\n",
    "    ).alias(\"comments_combined\")\n",
    "    ).drop([\"comment1\", \"comment2\", \"comment3\", \"comment4\", \"comment5\"])\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "n_samples = 80\n",
    "df_sampled = df.sample(n=n_samples, seed=RANDOM_SEED)\n",
    "documents = df_sampled.to_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8edb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ground_truth = pl.read_csv('../data/ground_truth.csv')\n",
    "\n",
    "ids_in_sample = df_sampled['id'].to_list()\n",
    "df_ground_truth_sampled = df_ground_truth.filter(pl.col(\"id\").is_in(ids_in_sample))\n",
    "ground_truth = df_ground_truth_sampled.to_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e9999e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>title</th><th>selftext</th><th>url</th><th>comments_combined</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;1n7nuhb&quot;</td><td>&quot;2 Week Itinerary Feedback&quot;</td><td>&quot;Hi guys, I’m looking for some …</td><td>&quot;https://www.reddit.com/r/Japan…</td><td>&quot;Comment 1: This feels like a l…</td></tr><tr><td>&quot;1fgrwdx&quot;</td><td>&quot;Back-to-back Kusatsu Onsen and…</td><td>&quot;In Nagano, we didn&#x27;t find much…</td><td>&quot;https://www.reddit.com/r/Japan…</td><td>&quot;Comment 1: There are some grea…</td></tr><tr><td>&quot;1n0490k&quot;</td><td>&quot;Itinerary and Suggestions - Si…</td><td>&quot;Hello,\n",
       "\n",
       "My sister and I are go…</td><td>&quot;https://www.reddit.com/r/Japan…</td><td>&quot;Comment 1: I see some amount o…</td></tr><tr><td>&quot;1nd0k84&quot;</td><td>&quot;3 week Itinerary feedback requ…</td><td>&quot;# Day 1&nbsp;&nbsp;— Arrival &amp; Shibuya/S…</td><td>&quot;https://www.reddit.com/r/Japan…</td><td>&quot;Comment 1: \n",
       "Comment 2: \n",
       "Commen…</td></tr><tr><td>&quot;1n8j5t2&quot;</td><td>&quot;Itinerary for relaxed first ti…</td><td>&quot;Hello everyone!&nbsp;&nbsp;\n",
       "My friend an…</td><td>&quot;https://www.reddit.com/r/Japan…</td><td>&quot;Comment 1: I would move all yo…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌─────────┬──────────────────────┬─────────────────────┬─────────────────────┬─────────────────────┐\n",
       "│ id      ┆ title                ┆ selftext            ┆ url                 ┆ comments_combined   │\n",
       "│ ---     ┆ ---                  ┆ ---                 ┆ ---                 ┆ ---                 │\n",
       "│ str     ┆ str                  ┆ str                 ┆ str                 ┆ str                 │\n",
       "╞═════════╪══════════════════════╪═════════════════════╪═════════════════════╪═════════════════════╡\n",
       "│ 1n7nuhb ┆ 2 Week Itinerary     ┆ Hi guys, I’m        ┆ https://www.reddit. ┆ Comment 1: This     │\n",
       "│         ┆ Feedback             ┆ looking for some …  ┆ com/r/Japan…        ┆ feels like a l…     │\n",
       "│ 1fgrwdx ┆ Back-to-back Kusatsu ┆ In Nagano, we       ┆ https://www.reddit. ┆ Comment 1: There    │\n",
       "│         ┆ Onsen and…           ┆ didn't find much…   ┆ com/r/Japan…        ┆ are some grea…      │\n",
       "│ 1n0490k ┆ Itinerary and        ┆ Hello,              ┆ https://www.reddit. ┆ Comment 1: I see    │\n",
       "│         ┆ Suggestions - Si…    ┆                     ┆ com/r/Japan…        ┆ some amount o…      │\n",
       "│         ┆                      ┆ My sister and I are ┆                     ┆                     │\n",
       "│         ┆                      ┆ go…                 ┆                     ┆                     │\n",
       "│ 1nd0k84 ┆ 3 week Itinerary     ┆ # Day 1  — Arrival  ┆ https://www.reddit. ┆ Comment 1:          │\n",
       "│         ┆ feedback requ…       ┆ & Shibuya/S…        ┆ com/r/Japan…        ┆ Comment 2:          │\n",
       "│         ┆                      ┆                     ┆                     ┆ Commen…             │\n",
       "│ 1n8j5t2 ┆ Itinerary for        ┆ Hello everyone!     ┆ https://www.reddit. ┆ Comment 1: I would  │\n",
       "│         ┆ relaxed first ti…    ┆ My friend an…       ┆ com/r/Japan…        ┆ move all yo…        │\n",
       "└─────────┴──────────────────────┴─────────────────────┴─────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sampled.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb464e3",
   "metadata": {},
   "source": [
    "# Minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "46dca060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x1895a640bb0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search(query):\n",
    "    boost = {'title':1.3, 'selftext': 1.2}\n",
    "\n",
    "    results = index.search(\n",
    "        query = query,\n",
    "        boost_dict = boost,\n",
    "        num_results = 5\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "index = minsearch.Index(\n",
    "        text_fields=[\"title\", \"selftext\", \"comments_combined\"],\n",
    "        keyword_fields = [\"id\", \"url\"]\n",
    "        )\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8e6f9f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(search_results, query):\n",
    "    prompt_template = \"\"\"\"\n",
    "    You are a helpful travel guide for people visiting Japan. \n",
    "    Answer the QUESTION based on the CONTEXT from travel discussions and experiences.  \n",
    "    Use only the facts from the CONTEXT when you are answering the QUESTION.  \n",
    "    If the CONTEXT does not contain enough information, say that you don’t know.  \n",
    "\n",
    "    QUESTION: {question}  \n",
    "\n",
    "    CONTEXT: {context}\n",
    "\n",
    "    \"\"\".strip()\n",
    "\n",
    "    max_docs = len(search_results)\n",
    "    context_parts = []\n",
    "    for i, doc in enumerate(search_results[:max_docs], start=1):\n",
    "        part = f\"\"\"\n",
    "            Document {i}:\n",
    "            Title: {doc.get('title', '')}\n",
    "            Post: {doc.get('selftext', '')}\n",
    "            Comments: {doc.get('comments_combined', '')}  \n",
    "        \"\"\"\n",
    "        context_parts.append(part.strip())\n",
    "        \n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "    prompt = prompt_template.format(question=query, context=context)\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b64b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cb74e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(search_results, query)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325c1f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_total = []\n",
    "llm_answers = []\n",
    "\n",
    "for r in ground_truth: \n",
    "    doc_id = r['id']\n",
    "\n",
    "    results = search(r['question'])\n",
    "    relevance = [d['id'] == doc_id for d in results]\n",
    "    relevance_total.append(relevance)\n",
    "\n",
    "    llm_ans = rag(r['question'])\n",
    "    llm_answers.append(llm_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4c676d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of llm-generated questions answered: 400\n",
      "total number of llm-generated questions: 2225\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of llm-generated questions answered: {len(llm_answers)}\")\n",
    "print(f\"total number of llm-generated questions: {len(df_ground_truth)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f6e52c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30008333333333337"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "    \n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank+1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "mrr(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e701874d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.0366\n"
     ]
    }
   ],
   "source": [
    "# calculate cosine similarity\n",
    "final_answer_number = len(llm_answers)\n",
    "\n",
    "corpus = [doc[\"comments_combined\"] for doc in documents] \n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "ground_truth_ans = df_ground_truth.select(pl.col('answer')).to_series().to_list()[:final_answer_number]\n",
    "gt_vectors = vectorizer.transform(ground_truth_ans)\n",
    "llm_vectors = vectorizer.transform(llm_answers[:final_answer_number])\n",
    "\n",
    "# gt_vectors and llm_vectors are sparse matrices of shape (n, vocab_size)\n",
    "similarities = []\n",
    "for i in range(len(ground_truth_ans)):\n",
    "    sim = cosine_similarity(gt_vectors[i], llm_vectors[i])[0][0]\n",
    "    similarities.append(sim)\n",
    "\n",
    "print(f\"Cosine similarity: {round(sum(similarities)/len(similarities), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0f5a51ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth ans: The traveler unexpectedly joined a local Japanese family for dinner, sharing stories and laughter with them for several hours.\n",
      "LLM ans retrieval: If you develop a UTI during your trip to Kyoto, you should consider visiting Kajita Urology, which has been highly recommended by others. Make sure to bring your passport or a valid driver's license for identification. While they may have a wait time of about 2 hours, the process is generally efficient. The clinic is open from 9:00-13:00 and 16:30-19:30, so plan accordingly. Additionally, to manage pain and symptoms before your appointment, you could try a herbal medication drink called \"JinSenSan,\" which has been reported to help alleviate symptoms. Be prepared to pay around 5,700 yen ($37) for the consultation, urine test, and antibiotics.\n",
      "\n",
      "Ground truth ans: Despite minimal Japanese language skills and the locals' limited English, they were able to communicate and form a connection through simple conversations and translations.\n",
      "LLM ans retrieval: The cost for a visit to Kajita Urology for a UTI treatment is up to 10,000 yen or more, but in the experience shared, the total cost for the doctor visit, urine test, and antibiotics was 5,700 yen (approximately $37).\n",
      "\n",
      "Ground truth ans: The highlight was bonding with the local Japanese group over dinner and drinks, experiencing genuine hospitality and friendship.\n",
      "LLM ans retrieval: I don’t know.\n",
      "\n",
      "Ground truth ans: She encouraged him to go out for dinner while she rested, and was happy to hear about his experiences afterward.\n",
      "LLM ans retrieval: You will need to bring your passport to Kajita Urology, as the receptionist specifically asked for it. However, if you do not have your passport, a valid driver's license can suffice.\n",
      "\n",
      "Ground truth ans: The traveler believes the essence lies in the connections made with people, highlighting the kindness and hospitality of the Japanese.\n",
      "LLM ans retrieval: I don’t know.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print(f\"Ground truth ans: {ground_truth_ans[i]}\")\n",
    "    print(f\"LLM ans retrieval: {llm_answers[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200266b9",
   "metadata": {},
   "source": [
    "## Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708f9afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name = \"travel-rec-sparse\"\n",
    "qd_client.delete_collection(collection_name)\n",
    "\n",
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "\n",
    "qd_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config = models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,  \n",
    "        distance=models.Distance.COSINE  \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ced2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------\n",
    "# Chunking Function\n",
    "# ----------------\n",
    "def chunk_text(\n",
    "    text: str, \n",
    "    doc_id: str, \n",
    "    chunk_size: int = 200, \n",
    "    overlap: int = 20\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Split text into overlapping chunks of words with unique IDs.\"\"\"\n",
    "    words = re.split(r\"\\s+\", text.strip())\n",
    "    \n",
    "    chunks = []\n",
    "    start = 0\n",
    "    chunk_num = 0\n",
    "\n",
    "    while start < len(words):\n",
    "        end = min(start + chunk_size, len(words))\n",
    "        chunk_words = words[start:end]\n",
    "        chunk_text = \" \".join(chunk_words)\n",
    "\n",
    "        chunks.append({\n",
    "            \"id\": f\"{doc_id}_{chunk_num}\",\n",
    "            'doc_id': doc_id,\n",
    "            \"text\": chunk_text\n",
    "        })\n",
    "\n",
    "        chunk_num += 1\n",
    "\n",
    "        if end == len(words) or len(words) - end <= overlap:\n",
    "            break\n",
    "        start = end - overlap\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "# ----------------\n",
    "# Embedding + Upsert\n",
    "# ----------------\n",
    "def upsert_documents(collection_name, docs):\n",
    "\n",
    "    all_chunks = []\n",
    "    for doc in docs:\n",
    "        text = f\"Title: {doc['title']}\\n\\nContent: {doc['selftext']}\\n\\nComments:\\n{doc['comments_combined']}\"\n",
    "        chunks = chunk_text(text, doc['id'], chunk_size=200, overlap=20)\n",
    "        all_chunks.extend(chunks)\n",
    "\n",
    "    # Build Qdrant points\n",
    "    points = [\n",
    "        models.PointStruct(\n",
    "            id=i, \n",
    "            vector=models.Document(text = doc['text'], model = model_handle),\n",
    "            payload={\"id\": doc[\"id\"], \"doc_id\": doc[\"doc_id\"], \"text\": doc[\"text\"]}\n",
    "        )\n",
    "        for i, doc in enumerate(all_chunks)\n",
    "    ]\n",
    "\n",
    "        # Upsert into Qdrant\n",
    "    qd_client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=points\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "55cd8bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsert_documents(collection_name, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "88021d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(query, limit = 1):\n",
    "    results = qd_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query = models.Document(\n",
    "            text = query,\n",
    "            model = model_handle\n",
    "        ),\n",
    "        limit = limit,\n",
    "        with_payload = True\n",
    "    )\n",
    "    return results.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b6899dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_vector_search(search_results, query):\n",
    "    prompt_template = \"\"\"\"\n",
    "    You are a helpful travel guide for people visiting Japan. \n",
    "    Answer the QUESTION based on the CONTEXT from travel discussions and experiences as concise as possible.  \n",
    "    Use only the facts from the CONTEXT when you are answering the QUESTION.  \n",
    "    If the CONTEXT does not contain enough information, say that you don’t know.  \n",
    "\n",
    "    QUESTION: {question}  \n",
    "\n",
    "    CONTEXT: {context}\n",
    "\n",
    "    \"\"\".strip()\n",
    "\n",
    "    max_docs = len(search_results)\n",
    "    context_parts = []\n",
    "    for i, result in enumerate(search_results[:max_docs], start=1):\n",
    "        doc = result.payload\n",
    "        part = f\"\"\"\n",
    "            Document {i}:\n",
    "            Text: {doc.get('text', '')}\n",
    "            Doc_id: {doc.get('doc_id', '')}\n",
    "            Id: {doc.get('id', '')}  \n",
    "        \"\"\"\n",
    "        context_parts.append(part.strip())\n",
    "        \n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "    prompt = prompt_template.format(question=query, context=context)\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a68e3569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest score is 0.84673715\n",
      "Doc_id: 1nbp784_0\n",
      "Title: Sep. - Oct. itinerary (Kanazawa/Tokyo with day trips) Content: Apologies in advance for the novel. My dad (55M) and I (28F) will be visiting Japan for the first time in a couple of weeks (Sep. 24 - Oct. 3) and I’d love to get some feedback on our itinerary. Other than the specific questions peppered throughout, I’d also appreciate input on the general feasibility of these plans. I figure some things will need to go but don't yet know how to choose. Notes: * I’ve been asked why we’re spending so much time in Kanazawa, and the answer is that my dad has to be there for work/educational reasons. Some activities will be on my own and others we will do together. The Tokyo plans are all for us to do together. * We’re interested in arts, culture, stationery, and handicrafts; I’m also interested in history, anime, and video games. * I have a chronic illness that impacts my energy levels and will be renting a power wheelchair to have as back-up (can still handle a little walking on bad days though). I realize that certain locations on the itinerary are not wheelchair-friendly, so my thinking is that if,\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "query = 'give me a feasible itinerary'\n",
    "limit = 3\n",
    "search_results = vector_search(query, limit)\n",
    "highest_score = search_results[0].score\n",
    "print(f\"The highest score is {highest_score}\")\n",
    "print(f\"Doc_id: {search_results[0].payload['id']}\")\n",
    "print(search_results[0].payload['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "802f3be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_vector_search(query):\n",
    "    search_results = vector_search(query, 1)\n",
    "    prompt = build_prompt_vector_search(search_results, query)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "224eceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_total = []\n",
    "llm_answers = []\n",
    "\n",
    "for r in ground_truth:\n",
    "    doc_id = r['id']\n",
    "\n",
    "    # get list for MRR\n",
    "    results = vector_search(r['question'], 5)\n",
    "    relevance = [d.payload['doc_id'] == doc_id for d in results]\n",
    "    relevance_total.append(relevance)\n",
    "\n",
    "    # get responses from llm\n",
    "    llm_ans = rag_vector_search(r['question'])\n",
    "    llm_answers.append(llm_ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cae6e45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6246249999999999"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "    \n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank+1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "mrr(relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a87f940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cosine similarity\n",
    "\n",
    "# embed the vectors\n",
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "embedding_model = TextEmbedding(model_name = model_handle)\n",
    "ground_truth_answers = df_ground_truth.select(pl.col('answer')).to_series().to_list()\n",
    "\n",
    "\n",
    "# Encode ground truth and LLM answers\n",
    "def cosine_similarity(ground_truth_ans, llm_ans):\n",
    "    gt_emb = list(embedding_model.embed(ground_truth_ans))\n",
    "    llm_emb = list(embedding_model.embed(llm_ans))\n",
    "\n",
    "    # calculate cosine similarity\n",
    "    def cosine(u, v):\n",
    "        u_norm = np.sqrt(u.dot(u))\n",
    "        v_norm = np.sqrt(v.dot(v))\n",
    "        return u.dot(v) / (u_norm * v_norm)\n",
    "\n",
    "    similarity_lst = []\n",
    "    for i in range(len(llm_emb)):\n",
    "        similarity = cosine(gt_emb[i], llm_emb[i])\n",
    "        similarity_lst.append(similarity)\n",
    "\n",
    "    return sum(similarity_lst) / len(similarity_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342833c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity is 0.7023\n"
     ]
    }
   ],
   "source": [
    "cos_similarity = cosine_similarity(ground_truth_answers, llm_answers)\n",
    "print(f\"The cosine similarity is {round(cos_similarity, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e8de2838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth ans: You can refer to Japan-Guide.com, Accessible Japan, Accessible Travel Japan, and the Japan Accessible Tourism Center for information.\n",
      "LLM ans retrieval: Watadzumi Shrine has prohibited entry to its grounds for all individuals except registered parishioners and devoted worshippers, due to a disrespectful incident by a foreign visitor. This includes banning photography, video recording, and participation in sightseeing tours.\n",
      "\n",
      "Ground truth ans: He was last seen at Shin Kiba station on Platform 1.\n",
      "LLM ans retrieval: The incident that prompted the shrine to restrict access to its grounds was an extremely serious and unacceptable act of disrespect committed within the sacred grounds by a foreign visitor on March 22.\n",
      "\n",
      "Ground truth ans: He is 62 years old, about 5 feet 2 inches tall, and has a mustache.\n",
      "LLM ans retrieval: The impact of disrespectful tourist behaviors on Watadzumi Shrine's operations has been significant. The shrine has prohibited entry to all tourists, restricting access only to registered parishioners and devoted worshippers. This includes a ban on all photography, video recording, and live streaming. The decision follows a serious act of disrespect by a foreign visitor and has caused immense psychological distress among shrine staff. The shrine is facing a crisis regarding its continued operation due to repeated desecration and abuse from tourists.\n",
      "\n",
      "Ground truth ans: You can contact the local police to file a missing person's report.\n",
      "LLM ans retrieval: The shrine's operators believe inbound tourism is a threat to Japanese culture because they feel that it leads to disrespectful behavior from some tourists, which is eroding the places, traditions, and values that the Japanese hold sacred.\n",
      "\n",
      "Ground truth ans: It's advisable to carry devices like an airtag for easy tracking in emergencies.\n",
      "LLM ans retrieval: Yes, Watadzumi Shrine has previously taken measures to restrict foreign visitors due to an incident involving disrespectful behavior by a foreign visitor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,15):\n",
    "    print(f\"Ground truth ans: {ground_truth_ans[i]}\")\n",
    "    print(f\"LLM ans retrieval: {llm_answers[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d295fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save llm answers\n",
    "# df_vector_search_results = df_ground_truth_sampled.with_columns(pl.Series(name=\"llm_answers\", values=llm_answers)) \n",
    "# df_vector_search_results.write_csv(\"../data/vector_search_results.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8df251",
   "metadata": {},
   "source": [
    "## Hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "56064d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the collection with specified sparse vector parameters\n",
    "collection_name = \"travel-rec-dense-and-sparse\"\n",
    "qd_client.delete_collection(collection_name)\n",
    "\n",
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "\n",
    "\n",
    "qd_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config = {\n",
    "        \"jina-small\": models.VectorParams(\n",
    "            size=512,\n",
    "            distance=models.Distance.COSINE,\n",
    "        ),        \n",
    "    },\n",
    "    sparse_vectors_config={\n",
    "        \"bm25\": models.SparseVectorParams(\n",
    "            modifier=models.Modifier.IDF,\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8d041c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_documents_hybrid(collection_name, docs):\n",
    "\n",
    "    all_chunks = []\n",
    "    for doc in docs:\n",
    "        text = f\"Title: {doc['title']}\\n\\nContent: {doc['selftext']}\\n\\nComments:\\n{doc['comments_combined']}\"\n",
    "        chunks = chunk_text(text, doc['id'], chunk_size=200, overlap=20)\n",
    "        all_chunks.extend(chunks)\n",
    "\n",
    "        # Build Qdrant points\n",
    "    points = [\n",
    "        models.PointStruct(\n",
    "            id=i, \n",
    "            vector={\n",
    "                \"jina-small\": models.Document(text = doc['text'], model = \"jinaai/jina-embeddings-v2-small-en\"),\n",
    "                \"bm25\":models.Document(text = doc['text'], model = \"Qdrant/bm25\")},\n",
    "            payload={\"id\": doc[\"id\"], \"doc_id\": doc[\"doc_id\"], \"text\": doc[\"text\"]}\n",
    "            \n",
    "        )\n",
    "        for i, doc in enumerate(all_chunks)\n",
    "    ]\n",
    "\n",
    "        # Upsert into Qdrant\n",
    "    qd_client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=points\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "31973ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsert_documents_hybrid(collection_name, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fc2c582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search\n",
    "def hybrid_search(query, limit):\n",
    "    results = qd_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        prefetch=[\n",
    "            models.Prefetch(query=models.Document(\n",
    "                text=query,\n",
    "                model='jinaai/jina-embeddings-v2-small-en',\n",
    "            ),\n",
    "            using='jina-small',\n",
    "            limit=limit,\n",
    "            ),\n",
    "            models.Prefetch(query=models.Document(\n",
    "                text=query,\n",
    "                model='Qdrant/bm25',\n",
    "            ),\n",
    "            using='bm25',\n",
    "            limit=limit)\n",
    "        ],\n",
    "        \n",
    "        query = models.FusionQuery(fusion=models.Fusion.RRF),\n",
    "        with_payload=True\n",
    "    )\n",
    "    return results.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "aaa2a0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1n7nuhb_1'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "query = 'give me a reasonably-paced itinerary for Tokyo'\n",
    "limit = 1\n",
    "\n",
    "results = hybrid_search(query,1)\n",
    "results[0].payload['text']\n",
    "results[0].payload['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb088bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_hybrid_search(query):\n",
    "    search_results = hybrid_search(query, 1)\n",
    "    prompt = build_prompt_vector_search(search_results, query) \n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bb63e803",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_total = []\n",
    "llm_answers = []\n",
    "document_retrieved = []\n",
    "\n",
    "for r in ground_truth:\n",
    "    doc_id = r['id']\n",
    "\n",
    "    # get list for MRR\n",
    "    results = hybrid_search(r['question'], 5)\n",
    "    relevance = [d.payload['doc_id'] == doc_id for d in results]\n",
    "    relevance_total.append(relevance)\n",
    "\n",
    "    # get responses from llm\n",
    "    llm_ans = rag_hybrid_search(r['question'])\n",
    "    llm_answers.append(llm_ans)\n",
    "\n",
    "    # save id of documents retrieved\n",
    "    result_docs = [d.payload['doc_id'] for d in results]\n",
    "    document_retrieved.append(result_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "cd9502b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs_json = [json.dumps(sublist) for sublist in document_retrieved]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87187f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to read the json string (replace retrieved_docs_json with the pd column)\n",
    "retrieved_docs_back = [json.loads(x) for x in retrieved_docs_json]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440bfa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hybrid_search= df_ground_truth_sampled.with_columns(\n",
    "#     pl.Series(name = \"retrieved_doc\", values = retrieved_docs_json),\n",
    "#     pl.Series(name = \"llm_answers\", values = llm_answers))\n",
    "# df_hybrid_search.write_csv(\"../data/hybrid_search_resuls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "224997d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.8100277777777772\n"
     ]
    }
   ],
   "source": [
    "print(f\"MRR: {mrr(relevance_total)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f220326a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity is 0.7101\n"
     ]
    }
   ],
   "source": [
    "cos_similarity = cosine_similarity(ground_truth_answers, llm_answers)\n",
    "print(f\"The cosine similarity is {round(cos_similarity, 4)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
